\documentclass[11pt, DIV=12]{scrartcl}
\usepackage[english]{babel}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}

\usepackage{graphicx}
\usepackage[numbers]{natbib}

\usepackage{subcaption}
\usepackage{booktabs}
\usepackage{url}
\usepackage{todonotes}
\usepackage{multirow}
\usepackage{tikz}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{thmtools}		
\usepackage{mleftright}
\usepackage{stmaryrd}
\usepackage{nicefrac}

\theoremstyle{definition}
\newtheorem{theorem}{Theorem}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{observation}[theorem]{Observation}
\newtheorem{remark}[theorem]{Remark}

\usepackage{thm-restate}
\usepackage[mathic=true]{mathtools}
\usepackage{fixmath}
\usepackage{siunitx}
\usepackage{color}

\usepackage{pifont}
\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%

\usepackage{enumitem}
\setlist[enumerate]{noitemsep, topsep=0.5\topsep}
\setlist[description]{noitemsep, topsep=0.5\topsep}
\setlist[itemize]{noitemsep, topsep=0.5\topsep}

\usepackage{setspace}
\usepackage[protrusion=true,expansion=false, activate={true,nocompatibility},final,kerning=true,spacing=true]{microtype}
\usepackage[]{microtype}
\usepackage{ellipsis}
\usepackage{xspace}
\usepackage{hfoldsty}

\usepackage{tcolorbox}
\usepackage{lmodern}

%\addtokomafont{disposition}{\rmfamily}
%\addtokomafont{descriptionlabel}{\rmfamily}

%\usepackage{newpxtext,newpxmath}
%\usepackage{classico}

%\usepackage[tt=false]{libertine}
%\usepackage[varqu]{zi4}
%\usepackage[libertine]{newtxmath}

\usepackage[
pdfa,
hidelinks,
pdftex, 
pdfdisplaydoctitle,
pdfpagelabels,
pdfauthor={},
pdftitle={},
pdfsubject={},
pdfkeywords={},
pdfproducer={Latex with the hyperref package},
pdfcreator={pdflatex}
]{hyperref}

% Let cleveref and thmtools work together
\makeatletter
\def\thmt@refnamewithcomma #1#2#3,#4,#5\@nil{%
	\@xa\def\csname\thmt@envname #1utorefname\endcsname{#3}%
	\ifcsname #2refname\endcsname
	\csname #2refname\expandafter\endcsname\expandafter{\thmt@envname}{#3}{#4}%
	\fi
}
\makeatother
\usepackage[capitalise,noabbrev]{cleveref}   
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\algdef{SE}{ParForAllLoop}{EndParForAllLoop}[1]{\textbf{parallel for}\(\mbox{#1}\) \textbf{do}}{\textbf{end}}

\newcommand{\new}[1]{\emph{#1}}

\DeclarePairedDelimiter{\norm}{\lVert}{\rVert}
\newcommand{\ra}[1]{\renewcommand{\arraystretch}{#1}}

\newcommand{\cA}{\ensuremath{{\mathcal A}}\xspace}
\newcommand{\cB}{\ensuremath{{\mathcal B}}\xspace}
\newcommand{\cC}{\ensuremath{{\mathcal C}}\xspace}
\newcommand{\cD}{\ensuremath{{\mathcal D}}\xspace}
\newcommand{\cF}{\ensuremath{{\mathcal F}}\xspace}
\newcommand{\cH}{\ensuremath{{\mathcal H}}\xspace}
\newcommand{\cN}{\ensuremath{{\mathcal N}}\xspace}
\newcommand{\cM}{\ensuremath{{\mathcal M}}\xspace}

\newcommand{\cO}{\ensuremath{{\mathcal O}}\xspace}
\newcommand{\cI}{\ensuremath{{\mathcal I}}\xspace}
\newcommand{\cP}{\ensuremath{{\mathcal P}}\xspace}
\newcommand{\cR}{\ensuremath{{\mathcal R}}\xspace}
\newcommand{\cS}{\ensuremath{{\mathcal S}}\xspace}
\newcommand{\cU}{\ensuremath{{\mathcal U}}\xspace}
\newcommand{\cV}{\ensuremath{{\mathcal V}}\xspace}
\newcommand{\cPn}{\ensuremath{{\mathcal P}_n}\xspace}

\newcommand{\fA}{\ensuremath{\mathfrak{A}}\xspace}
\newcommand{\fB}{\ensuremath{\mathfrak{B}}\xspace}
\newcommand{\fC}{\ensuremath{\mathfrak{C}}\xspace}

\newcommand{\fa}{\ensuremath{\mathfrak{a}}\xspace}
\newcommand{\fb}{\ensuremath{\mathfrak{b}}\xspace}
\newcommand{\fc}{\ensuremath{\mathfrak{c}}\xspace}
\newcommand{\fd}{\ensuremath{\mathfrak{d}}\xspace}

\newcommand{\bA}{\ensuremath{{\bf A}}\xspace}
\newcommand{\bB}{\ensuremath{{\bf B}}\xspace}
\newcommand{\bK}{\ensuremath{{\bf K}}\xspace}
\newcommand{\bE}{\ensuremath{{\bf E}}\xspace}
\newcommand{\bN}{\ensuremath{{\bf N}}\xspace}
\newcommand{\bG}{\ensuremath{{\bf G}}\xspace}

\newcommand{\ba}{\ensuremath{{\bf a}}\xspace}
\newcommand{\bb}{\ensuremath{{\bf b}}\xspace}
\newcommand{\bc}{\ensuremath{{\bf c}}\xspace}

\newcommand{\bbE}{\ensuremath{\mathbb{E}}}
\newcommand{\bbR}{\ensuremath{\mathbb{R}}}
\newcommand{\bbQ}{\ensuremath{\mathbb{Q}}}
\newcommand{\bbP}{\ensuremath{\mathbb{P}}}
\newcommand{\bbZ}{\ensuremath{\mathbb{Z}}}
\newcommand{\bbN}{\ensuremath{\mathbb{N}}}
\newcommand{\bbNn}{\ensuremath{\mathbb{N}_0}}

\newcommand{\bbRnp}{\ensuremath{\bbR_{\geq 0}}}
\newcommand{\bbQnp}{\ensuremath{\bbQ_{\geq}}}
\newcommand{\bbZnp}{\ensuremath{\bbZ_{\geq}}}

\newcommand{\bbRsp}{\ensuremath{\bbR_>}}
\newcommand{\bbQsp}{\ensuremath{\bbQ_>}}
\newcommand{\bbZsp}{\ensuremath{\bbZ_>}}

\newcommand{\cp}{\textsf{P}\xspace}
\newcommand{\cnp}{\textsf{NP}\xspace}

\newcommand{\RR}{\mathbb{R}}
\newcommand{\QQ}{\mathbb{Q}}
\newcommand{\PP}{\mathbb{P}}
\newcommand{\ZZ}{\mathbb{Z}}
\newcommand{\EE}{\mathbb{E}}
\newcommand{\NN}{\mathbb{N}}
\newcommand{\GG}{\mathbb{G}}
\newcommand{\GN}{\mathbb{G}_n}

\newcommand{\rb}{\right\}\xspace}
\newcommand{\lb}{\left\{\xspace}
\newcommand{\lbr}{\left(\xspace} 
\newcommand{\rbr}{\right)\xspace}
\newcommand{\ndelta}{\ensuremath{\overline{\delta}}}

\newcommand{\oms}{\{\!\!\{}
\newcommand{\cms}{\}\!\!\}}

\newcommand{\trans}{^\mathsf{T}}
\renewcommand{\vec}[1]{\mathbf{#1}}
%\renewcommand{\vec}[1]{#1}

\usepackage[auth-lg]{authblk}
\newcommand{\cm}[1]{{{\textcolor{blue}{\textbf{[CM:} {#1}\textbf{]}}}}}
\newcommand{\ebk}[1]{{{\textcolor{green}{\textbf{[EBK:} {#1}\textbf{]}}}}}
\renewcommand*{\Affilfont}{\normalsize\normalfont}
\renewcommand*{\Authfont}{\sffamily}

\recalctypearea


\begin{document}
\title{MIP-GNN: A data-driven tool for guiding combinatorial solvers}
\author[1]{Elias B.~Khalil}
\author[2]{Christopher Morris}

\affil[1]{CERC in Data Science for Real-Time Decision-Making, Polytechnique Montr{\'e}al}	
\affil[2]{Department of Mechanical \& Industrial Engineering, University of Toronto}
\date{\vspace{-30pt}}

\maketitle

\begin{abstract}
Write abstract. Theme: general data-driven tool for replacing heuristic components of MIP solvers.	
	

\end{abstract}

\section{Introduction}
Write introduction, main points (MIP-GNN is a general purpose tool for guiding decision throughout the solving process of MIPs in a data-driven way):
\begin{itemize}
	\item MIPs solvers use many heuristics throughout solving process, need for data-driven heuristics that adapt to the problem distribution
	\item Graphs as a natural way to represent BIPs/ILPs/MIPs and other constraint convex optimization problems, graphs are a natural inductive bias
	\item Arguments of Fischetti 
\end{itemize}

\paragraph{Present work} Contribution.
\begin{itemize}
	\item General approach, many different applications within the MIP/B\&C solving framework, list examples
	\item Connection to MWU problem (theoretically principled, MWU can be recovered)
	\item Experimental evaluation on real-world instances, speed-up of $X$
\end{itemize}

\paragraph{Related work} Discuss related work.
\begin{itemize}
	\item GNNs to solve MIPs/comb. optimization problems, \cite{Li+2018b}, \cite{Vel+2020}, \cite{Gas+2019} \cite{Gup+2020} \cite{Kha+2016}, paper by Bistra Dilkina: \cite{Fer+2020} \cite{Son+2020} \cite{Wil+2019} \cite{Kha+2016b}, Paper by Lodi \cite{Ben+2018}, \cite{Lar+2018}, \cite{Bon+2018}, \cite{Ben+2019}, \cite{Fis+2019}, \cite{Gup+2020}, \cite{Zar+2020},	
	Paper of bello, kool	1qÂ§
	
	\item Papers on SAT and CSP solving (Hsu, LeSong, Aachen, Loukas \dots) \cite{Sel+2019}
\end{itemize}
 

GNN: Recently, graph neural networks (GNNs)~\cite{Gil+2017,Sca+2009} emerged as a flexible framework for machine learning on graphs and relational data. Notable instances of this architecture include, e.g.,~\cite{Duv+2015,Ham+2017,Vel+2018}, and the spectral approaches proposed in, e.g.,~\cite{Bru+2014,Def+2015,Kip+2017,Mon+2017}---all of which descend from early work in~\cite{Kir+1995,Mer+2005,Spe+1997,Sca+2009}. A survey of recent advancements in GNN techniques can be found, e.g., in~\cite{Cha+2020,Wu+2019,Zho+2018}. The limits of GNNs have been studied in~\cite{Bar+2020,Che+2019,Mae+2019,Mar+2019,Mor+2019,Xu+2018b}.


\section{Preliminaries}

In the following, we fix notation and give a short introduction to GNNs, binary integer programs, and setup the learning program.

\subsection{Notation}

\cm{shorten}
A \new{graph} $G$ is a pair $(V,E)$ with a \emph{finite} set of
\new{vertices} $V$ and a set of \new{edges} $E \subseteq \{ \{u,v\}
\subseteq V \mid u \neq v \}$. We denote the set of vertices and the set
of edges of $G$ by $V(G)$ and $E(G)$, respectively. For ease of
notation, we denote the edge $\{u,v\}$ in $E(G)$ by $(u,v)$ or
$(v,u)$. In the case of \emph{directed graphs} $E \subseteq \{ (u,v)
\in V \times V \mid u \neq v \}$. A \new{labeled graph} $G$ is a triple
$(V,E,l)$ with a label function $l \colon V(G) \cup E(G) \to \Sigma$,
where $\Sigma$ is some finite alphabet. Then $l(v)$ is a
\new{label} of $v$ for $v$ in $V(G) \cup E(G)$. 
The \new{neighborhood} 
of $v$ in $V(G)$ is denoted by $\delta(v) = N(v) = \{ u \in V(G) \mid (v, u) \in E(G) \}$. 
Moreover, its complement $\ndelta(v) = \{ u \in V(G) \mid (v, u) \notin E(G) \}$. 
Let $S \subseteq
V(G)$ then $G[S] = (S,E_S)$ is the \new{subgraph induced} by $S$ with
$E_S = \{ (u,v) \in E(G) \mid u,v \in S \}$. A \new{tree} is a connected graph without
cycles. A \new{rooted tree} is a tree with a designated vertex called \new{root} in which the edges are directed in such a way that they point away from the root. \cm{biparite graph}
Let $p$ be a vertex in a directed tree then we call its out-neighbors \new{children} with parent $p$. 
\cm{Add matrix notation, all-row vectors}
We say that two graphs $G$ and $H$
are \new{isomorphic} if there exists an edge preserving bijection
$\varphi \colon V(G) \to V(H)$, i.e., $(u,v)$ is in $E(G)$ if and only if
$(\varphi(u),\varphi(v))$ is in $E(H)$. If $G$ and $H$ are isomorphic,
we write $G \simeq H$ and call $\varphi$ an \new{isomorphism} between
$G$ and $H$. Moreover, we call the equivalence classes induced by
$\simeq$ \emph{isomorphism types}, and denote the isomorphism type of $G$ by
$\tau_G$. In the case of labeled graphs, we additionally require that
$l(v) = l(\varphi(v))$ for $v$ in $V(G)$ and $l((u,v)) = l((\varphi(u), \varphi(v)))$ for $(u,v)$ in $E(G)$. 
Moreover, let $[n] = \{ 1, \dotsc, n \} \subset \NN$ for $n \geq 1$, and let $\{\!\!\{ \dots\}\!\!\}$ denote a multiset. 


\subsection{Binary integer programs}\label{bip}

An \emph{instance} $I$ of binary integer program (BIP) is a $3$-tuple $(\vec{c}, \vec{A}, \vec{b})$, with a vector $\vec{c}$ in a matrix $\vec{A}$ in $\RR^{n \times m}$, and $\vec{b}$ in $\RR^{m}$. We interpret the former as a (linear) \new{objective} or \new{cost function}, and the latter two  are interpreted as a system of linear equations, i.e., $\vec{A} \vec{x} \geq \vec{b}$, which induces a set of \emph{feasible solutions} $F(I) = \{ \vec{x} \in \RR^n \mid \vec{A} \vec{x} \geq \vec{b}, \vec{x} \geq 0 \}$. We call each component of $\vec{x}$ a \new{variable}, and the set $\cV(I) = \{x_i \}_{i \in [n]}$ the (set of) variables.

The \new{optimal integral solution} $\vec{x}^*$ is equal to $\arg\max_{\vec{x} \in \{0,1\}^n} \{ \vec{c}\trans \vec{x} \mid \vec{A} \vec{x} \geq \vec{b}, \vec{x} \geq 0  \}$, i.e., we maximize the linear functional $\vec{c}$ over $F(I)_{0,1} = F(I) \cap \{ 0,1 \}^n$. The \emph{optimal solution} $\bar{\vec{x}}$ of the \new{relaxed BIP} is obtained by dropping the integrality contraints, i.e., $\vec{\bar{x}} = \arg\max_{\vec{x} \in [0,1]^n} \{ \vec{c}\trans \vec{x} \mid \vec{A} \vec{x} \geq \vec{b}, \vec{x} \geq 0 \}$. In other words, we maximize the linear functional $\vec{c}$ over $F(I)$.


\cm{State connection to comb. optimization}
\cm{Background on bb, branching etc}

\subsection{Graph neural networks}
Let $G$ be a labeled graph $(V,E,l)$ with an initial vertex coloring $f^{(0)} \colon V(G)\rightarrow \RR^{1\times d}$ that is \emph{consistent} with $l$. That is, each vertex $v$ is annotated with a feature $\vec{f}^{(0)}(v)$ in $\bbR^{1\times d}$ such that $\vec{f}^{(0)}(u) = \vec{f}^{(0)}(v)$ if and only if $l(u) = l(v)$.
Alternatively, $\vec{f}^{(0)}(v)$ can be an arbitrary  real-valued feature vector associated with $v$. A GNN architecture consists of a stack of neural network layers, where each layer aggregates local neighborhood information, i.e., features of neighbors, and then passes this aggregated information on to the next layer.  In each round or layer $t$ a new feature $\vec{f}^{(t)}(v)$ is computed as
\begin{equation}\label{eq:gnngeneral}
f^{\vec{W_2}}_{\textsc{Up}}\Big(\vec{f}^{(t-1)}(v) ,f^{\vec{W_1}}_{\textsc{Agg}}\big(\oms  \vec{f}^{(t-1)}(w) \mid  w \in N(v) \cms \big)\Big),
\end{equation}
where $f^{\vec{W_1}}_{\text{aggr}}$ aggregates over the set of neighborhood features and $f^{\vec{W_2}}_{\text{merge}}$ merges the vertex's representations from step $(t-1)$ with the computed neighborhood features.
Both $f^{\vec{W_1}}_{\text{aggr}}$ and $f^{\vec{W_2}}_{\text{merge}}$ may be arbitrary differentiable, (permutation-invariant) functions (e.g., neural networks), and $\vec{W_1}$ and $\vec{W_2}$, respectively, denote sets of parameters.



\subsection{Setup of the learning problem}
Let $\cC$ be the set of all instances of a combinatorial optimization problem that can be formulated as a BIP. Let $I$ be an instance in $\cC$, then let $X^*_{\varepsilon}(I) = \{ \vec{x} \in F_{0,1}(I) \mid \vec{c}\trans\vec{x}^* - \vec{c}\trans\vec{x} \leq \varepsilon \}$ be a set of integral solutions that are \glqq close\grqq{}  to the optimum of the instance $I$. That is, their solution value is equal to the optimal value up to a prespecified $\varepsilon$. The \new{variable bias} $\vec{\bar{b}}(I)$ of $I$ with regard to $X^*_{\varepsilon}(I)$  then is the component-wise average over all elements, i.e., the variable bias $\vec{\bar{b}}(I) = \nicefrac{1}{|X^*_{\varepsilon}|}\sum_{\vec{x} \in X^*_{\varepsilon}(I)} \vec{x}$ in $\bbR^n$.

The aim here is to devise a neural architecture and train a corresponding model in  a supervised fashion to predict the variable bias $\vec{\bar{b}}(I)$ for unseen instances. Hence, let $D$ be a distribution over $\cC$ and let $S$ be a finite subset (training set) sampled uniformly and at random from $D$. We want to learn a function $f_{\theta} \colon \cV(I) \to \RR$, where $\theta$ represents a set of parameters in the set $\Theta$, that predicts the variable biases of out-of-sample instances. Hence, we optimize the empirical error
\begin{equation*}
\min_{\theta \in \Theta} \nicefrac{1}{|S|}\sum_{I \in S} \ell(f_{\theta}(\cV(I)),\vec{\bar{b}}(I)),
\end{equation*}
with some loss function $\ell \colon \bbR^n \times \bbR^n \to \bbR$ over the set of parameters $\Theta$.

\cm{Combination of GNN and MWU }


\subsection{Multiplicative weights update algorithm for linear programs}

The \new{multiplicative weights update algorihm} (MWU) is a framework to solve various computational problems that can be solved by iterativly adapting a discrete probability distribution over a certain set~\cite{Aro+2012}. Here, we describe the variant of the MWU to determine the feasibility of a system of a system of linear equations. 

Given a system of linear equations $\vec{A} \vec{x} \geq \vec{b}$, see~\cref{bip}, the MWU tries to determine if the above system is feasible up to a prespecified $\varepsilon > 0$. That is, it determines if there exists $\vec{\bar{x}}$ such that 
\begin{equation}\label{epsfeas}
\vec{A}_i \vec{\bar{x}} \geq b_i - \varepsilon,
\end{equation}
for $i$ in $[m]$.\cm{say sth. about optimal solution, give intution of the MWU, discrete prob., oracle for LP, Farkas' lemma.}

%\begin{algorithm}[H]\mbox{\hfill}
%	\\\textbf{Input:} System of linear equations $\vec{A} \vec{x} \geq \vec{b}$, $\varepsilon > 0$,  stepsize $\eta > 0$, scaling constant $\rho$. \\
%	\textbf{Output:} $\vec{\bar{x}}$ satisfying~\cref{epsfeas} or \texttt{non-feasible}.
%	\begin{algorithmic}[1]
%		\State Initialize constraint weights $\vec{w}_i \leftarrow 1$ for $i$ in $[m]$ 
%		\State Initialize probabilities $\vec{p}_j \leftarrow \nicefrac{1}{m}$ for $i$ in $[m]$ 
%		\State Set $T$ to according~\cref{mwubound}
%		\For{$t \text{ in } [T]$}
%		
%		\State Call oracle: $\vec{x} \leftarrow \cO(\vec{p}\trans \vec{A} \vec{x} \geq \vec{p}\trans \vec{b})$, \textbf{if} $
%		\vec{x} = \emptyset$ \Return  \texttt{non-feasible}
%		\State Compute error signal $\vec{e}$, where
%		\begin{equation*}
%		\vec{e}_j \leftarrow \nicefrac{1}{\rho}\,(\vec{A}_j\trans \vec{x}(t) - \vec{b}_j)   
%		\end{equation*}
%		\State Perform gradient descent by $\vec{w}_i \leftarrow (1 - \eta \vec{e}_i) \vec{w}_i$ 
%		\State Normalize weights $\vec{p}_j \leftarrow \nicefrac{\vec{w}_j}{\boldsymbol{\Gamma}(t)} $  for $i$ in $[m]$, where $\boldsymbol{\Gamma}(t) = \sum_{i \in [m]} \vec{w}_i$
%		\State Update solution $\vec{\bar{x}} \leftarrow \vec{\bar{x}} + \vec{x}$
%		\EndFor
%		\State \Return Average over solution $ \nicefrac{\vec{\bar{x}}}{T} $
%	\end{algorithmic}
%	\caption{MWU for the LP feasibility problem.}
%	\label{alg:as}
%\end{algorithm}
\cm{exploration/exploitation $\eta$}
Same algorithm as above interpreted as a message passing algorithm:
\begin{algorithm}[H]\mbox{\hfill}
	\\\textbf{Input:} Biparite constraint graph $B(I)$, $\varepsilon > 0$,  stepsize $\eta > 0$, scaling constant $\rho$. \\
	\textbf{Output:} $\vec{\bar{x}}$ satisfying~\cref{epsfeas} or \texttt{non-feasible}.
	\begin{algorithmic}[1]
		\State Initialize weights $\vec{w}_j \leftarrow 1$ for each constraint node
		\State Initialize probabilities $\vec{p}_j \leftarrow \nicefrac{1}{m}$ for each constraint node
		\State Set $T$ to according~\cref{mwubound}
		\For{$t \text{ in } [T]$}
		\State For each constraint node $\vec{c}_j$ send $\vec{p}_j$ to adjacent node variable
		\Statex
		\State Update each variable node $\vec{v}_i$ based on output $\vec{x}_i$ of oracle using $\vec{p}$
		\State Send $\vec{v}_i$ to each adjacent constraint, compute error signal $\vec{e}_i$ for each constraint $\vec{c}_j$
		\begin{equation*}
		\vec{e}_j \leftarrow \nicefrac{1}{\rho}\,\Big(\sum_{i \in N(j)} \label{key}\vec{A}_{ji}  \vec{v}_i \Big) - \vec{b}_j   
		\end{equation*}
		\State Perform gradient descent by $\vec{w}_i \leftarrow (1 - \eta \vec{e}_i) \vec{w}_i$ 
		\State Normalize weights $\vec{p}_j \leftarrow \nicefrac{\vec{w}_j}{\boldsymbol{\Gamma}(t)} $  for $i$ in $[m]$, where $\boldsymbol{\Gamma}(t) = \sum_{i \in [m]} \vec{w}_i$
		\State Update solution $\vec{\bar{x}} \leftarrow \vec{\bar{x}} + \vec{x}$
		\EndFor
		\State \Return Average over solution $ \nicefrac{\vec{\bar{x}}}{T}$
	\end{algorithmic}
	\caption{MWU (Message passing version) for the LP feasibility problem.}
	\label{alg:as}
\end{algorithm}

We get the following bound of the running time.
\begin{theorem}[E.g., \cite{Aro+2012}]
	\cm{fill in details}
	\begin{equation}\label{mwubound}
		T = \left\lceil \frac{8 l \rho \ln(m)}{\varepsilon^2} \right\rceil 
	\end{equation}
\end{theorem}

\section{The MIP-GNN architecture}


Let $I = (\vec{c}, \vec{A}, \vec{b})$ be a BIP. The bipartite graph $B(I)$ of $I$ is three tuple $(V(I),C(I),E(I))$. Here, the vertex set $V(I) = \{ v_i \mid x_i \in \cV(I) \}$ represent the variables, and the set $C(I) = \{ c_i \mid i \in [m]  \}$ represent the constraints of $I$. The edge set $E(I) = \{ \{ v_i,c_j \} \mid A_{ij} \neq 0 \}$. Further, we define (node) label function $c\colon V(I) \to \bbR$, defined by $v_i \mapsto c_i$, and the (edge) label function $a \colon E(I) \to \bbR$, defined by  $(v_i,v_j) \mapsto A_{ij}$.
\cm{add more label functionsÂ }


Intuitively, each round $t \geq 0$ of message-passing consists of two \emph{passes}, the \new{variable to constraint} $f^{(t)}_{\text{V$\to$C}}\colon C(I) \to \RR^{1\times d}$ pass, followed by the \text{constraint to variable} pass $f^{(t)}_{\text{C$\to$V}}\colon V(I) \to \RR^{1\times d}$. 
\cm{Say sth. about the initialiazation, gaussian?}
\cm{Say sth. about cost }
In the following, we gives details about the two passes. 



\paragraph{Variable to constraints.} 


\paragraph{Constraint to variable:} sdfdsf

%
%\begin{algorithm}[H]\mbox{\hfill}
%	\\\textbf{Input:}  Training set $\cS$, $\varepsilon > 0$, number of epochs $E$, number of rounds $T$, stepsize $\eta > 0$, scaling constant $\rho$.  \\
%	\textbf{Output:} A trained model $f_{\boldsymbol{\theta}} \colon \cI \to [0,1]^n$.
%	\begin{algorithmic}[1]
%		\State Initialize $\vec{v}_i^{(0)}$, $\vec{c}_i^{(0)}$
%		\State Initialize parameters $\boldsymbol{\theta} = (\boldsymbol{\theta}_{\text{V}}$, $\boldsymbol{\theta}_{\text{C}}$, $\boldsymbol{\theta}_{\text{X}})$
%		\State Set weights $\vec{w}_j^{(0)} \leftarrow 1$, $\vec{p}_j^{(0)} \leftarrow \nicefrac{1}{m}$ for $j$ in $[m]$
%		\For{$e \text{ in } [E]$}
%		\State Sample $I = (\vec{c}, \vec{A}, \vec{b})$ with variable bias $\vec{\bar{b}}$ uniformly and at random from $\cS$, inducing the bipartite graph $B(I)$
%		\For{$t \text{ in } [T]$}
%		\State $\vec{v}_i^{(t)} \leftarrow {f}^{(t)}_{\text{V}} \hspace{-1pt} \big( \big\{ \hspace{-4.4pt} \big\{ \big( \vec{v}^{(t-1)}_i, \vec{c}^{(t-1)}_j, \vec{p}^{(t-1)}_j, \vec{A}_{ji} \big)\hspace{-1pt} \colon c_j \in N(v_i) \big\} \hspace{-4.4pt} \big\} \big)$ for all $i$ in $[n]$ 		
%		
%		\State $\vec{x}_i^{(t)} \leftarrow {f}^{(t)}_{\text{X}} \hspace{-2pt} \left(\vec{v}_i^{(t-1)} \right)$ for all $i$ in $[n]$ 
%		\Statex
%		\Statex
%		\State $\vec{c}_j^{\hspace{1pt}(t)} \leftarrow {f}^{(t)}_{\text{C}} \hspace{-2pt} \left( \left\{ \hspace{-4.4pt} \left\{ \left( \vec{c}^{(t-1)}_j, \vec{v}^{(t)}_i, \vec{x}^{(t)}_i, \vec{A}_{ji}, \vec{b}_j \right)\hspace{-2pt} \colon i \in N(c_j) \right\} \hspace{-4.4pt} \right\} \right)$ for all $j$ in $[m]$ 	
%		\State $\vec{e}_j^{(t)} \, \leftarrow \nicefrac{1}{\rho}\,\Big(\sum_{i \in N(j)} \label{key}\vec{A}_{ji}  \vec{x}_i \Big) - \vec{b}_j$
%		%\Statex
%		\State $\vec{w}_j^{(t)} \leftarrow ( 1 -  \eta \vec{e}^{(t)}_j) \vec{w}_j^{(t-1)} $ 
%		\State $\vec{p}_j \leftarrow \nicefrac{w_j^{(t)}}{\boldsymbol{\Gamma}(t)} $, where $\boldsymbol{\Gamma}(t) = \sum_{j \in [m]} \vec{w}^{(t)}_j$
%		\State Update solution $\vec{\bar{x}} \leftarrow \vec{\bar{x}} + \vec{x}$
%		\EndFor
%		\State $\vec{\bar{x}} \leftarrow \nicefrac{1}{T} \sum_{t \in [T]} \vec{x}(t) $
%		\State $L \leftarrow L + \ell(\vec{\bar{x}}, \vec{\bar b})$ 
%		\State Gradient descent on $\nicefrac{1}{T} L$ with regard to $\boldsymbol{\theta}$
%		\EndFor
%		\State \Return $\boldsymbol{\theta}$
%		
%	\end{algorithmic}
%	\caption{Data-driven MWU for variable bias prediction.}
%	\label{alg:as2}
%\end{algorithm}

\cm{overloading of c}
\cm{how to incoperate data information}


\begin{algorithm}[H]\mbox{\hfill}
	\\\textbf{Input:}  Training set $S$, number of epochs $E$, number of layers $T$.  \\
	\textbf{Output:} A trained model $f_{\boldsymbol{\theta}} \colon \cI \to [0,1]^n$.
	\begin{algorithmic}[1]
		\State Initialize $\vec{v}^{(0)}$, $\vec{c}^{(0)}$, and $\vec{p}_i^{(0)}$
		\Statex
		\For{$e \text{ in } [E]$}
		\State Sample $I = (\vec{c}, \vec{A}, \vec{b})$ from $U(S)$ 
		\For{$t \text{ in } [T]$}
		\State $\vec{V}_j^{(t)} \leftarrow f_{\textsc{Var}}^{(t)} \hspace{-1pt} \big( \big\{ \hspace{-4.4pt} \big\{ \big( \vec{V}^{(t-1)}_j, \vec{C}^{(t-1)}_j, \vec{p}^{(t-1)}_i, \vec{A}_{ij} \big)\hspace{-1pt} \mid c_i \in N(v_j) \big\} \hspace{-4.4pt} \big\} \big)$ for all $j$ in $[n]$ 		
		\State $\vec{X}_j^{(t)} \leftarrow f_\textsc{Assn}^{(t)} \hspace{-2pt} \big(\vec{V}_j^{(t-1)} \big)$ 
		\Statex
		%\State \textit{Compute constraint embedding:}
		\State $\vec{C}_i^{\hspace{1pt}(t)} \leftarrow f_\textsc{Con}^{(t)} \hspace{-2pt} \big( \big\{ \hspace{-4.4pt} \big\{ \big( \vec{C}^{(t-1)}_i, \vec{V}^{(t)}_i, \vec{X}^{(t)}_i, \vec{A}_{ij}, \vec{b}_i \big)\hspace{-2pt} \mid v_i \in N(c_j) \big\} \hspace{-4.4pt} \big\} \big)$ for all $i$ in $[m]$ 	
		%\State $\vec{e}_j^{(t)} \leftarrow \sum_{i \in N(j)} \label{key}\vec{A}_{ji}  \vec{x}_i - \vec{b}_j$
		%\Statex

		\State $\vec{p}_{i}^{(t)} \hspace{3pt}\leftarrow \text{softmax}(f_\textsc{Prob}^{(t)}(\vec{e}^{(t)}))_{i}$
		%\begin{equation*}
		%\vec{e}_j \leftarrow \nicefrac{1}{\rho}\,\Big(\sum_{i \in N(j)} \label{key}\vec{A}_{ji}  %\vec{v}_i \Big) - \vec{b}_j   
		%\end{equation*}
		\EndFor
		\State $\bar{\vec{X}}_j \leftarrow f_\textsc{Mrg}(\mathbin\Vert_{t \in [T]} \vec{X}_j^{(t)})$
		\State $L \leftarrow L + \ell(\vec{\bar{X}}, \vec{\bar b})$ 
		\State Gradient descent  with regard to $\boldsymbol{\theta}$
		\EndFor
		\State \Return $\boldsymbol{\theta}$
		
	\end{algorithmic}
	\caption{MIP-GNN for variable bias prediction.}
	\label{alg:as2}
\end{algorithm}

\begin{equation}\label{err}
\vec{e}_i \leftarrow \nicefrac{1}{\rho}\,\Big(\sum_{j \in N(i)} \vec{A}_{ij}  \vec{X}_j \Big) - \vec{b}_i   
\end{equation}



Initialize parameters $\boldsymbol{\theta} = (\boldsymbol{\theta}_{\text{V}}$, $\boldsymbol{\theta}_{\text{C}}$, $\boldsymbol{\theta}_{\text{X}}, \boldsymbol{\theta}_{\text{P}})$



\subsection{Sample complexity/theoretical justification}

\cm{Show that our architecure offers better then generalization than simple, shallow MLP.}
\cm{Proof idea: show that GNN can be seen as low "degree" (assuming low nnz) compositional functions encoded as a tree, then use results on composiotional function (smaller set of parameters) to derive generalization bounds, Problem: (1) we are ingnoring the invariances here (should be okay as incoperating invariances are only improving sample complexity) (2) f}


\cm{Somehow show that architecture of Alg. 2 (MWU) is better than using a standard GNN. Idea: Show that MWU can be recovered to show that we always get an (epsilon) feasible solution (on the test data)}

\cm{Connection to Stefanies and Keyulus reasoning paper}

\subsection{Unsupervised setting}

random matrices, recover MWU, also test in experiments


\subsection{Discussion: Road blocks and the road ahead}
						
discuss limitation of GNNs approaches (bipartite GNN), unsupervised approaches

discuss problems of generating labeled training data

\section{Experimental evaluation}

Our intention here is to investigate the benefits of ... the compared to...
More precisely, we address the following questions:\\

\cm{}
\begin{description}
	\item[Q1] description
	\item[Q2] description
	\item[Q3] description
\end{description}

\section{Conclusion}
Write conclusion.			
\bibliography{bibliography}
\bibliographystyle{plainnat} 

	
\end{document}
